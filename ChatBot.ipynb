{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lines=open('../input/movie_lines.txt',encoding='utf=8',errors='ignore').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation=open('../input/movie_conversations.txt',encoding='utf=8',errors='ignore').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=pd.DataFrame(Lines)\n",
    "c=pd.DataFrame(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0\n",
      "0  L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++...\n",
      "1  L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON ++...\n",
      "2  L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$...\n",
      "3  L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++...\n",
      "4  L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$...\n",
      "                                                   0\n",
      "0  u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L19...\n",
      "1  u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\n",
      "2  u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L20...\n",
      "3  u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L20...\n",
      "4  u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']\n"
     ]
    }
   ],
   "source": [
    "print(l.head())\n",
    "print(c.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2line={} # making dictionary for id : line data \n",
    "for line in Lines:\n",
    "    _line=line.split(' +++$+++ ') #saving it in temp veriable\n",
    "   # print(_line)\n",
    "    if len(_line)==5:  #L925  u0  m0  BIANCA Tons\n",
    "        id2line[_line[0]]=_line[4]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#id2line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conversation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversationIds=[]\n",
    "for conver in conversation[:-1]:# last element is a blank ...(-1),removing [] by [1:-1],then will use replace \n",
    "    _conversation=conver.split(' +++$+++ ')[-1][1:-1].replace(\"'\",'').replace(' ','')\n",
    "    conversationIds.append(_conversation.split(','))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conversationIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Questions=[]\n",
    "Answers=[]\n",
    "for conver in conversationIds:\n",
    "    for i in range(len(conver)-1):\n",
    "        Questions.append(id2line[conver[i]])# id2line is a dictionary ,conver [i] becames the key\n",
    "        Answers.append(id2line[conver[i+1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now cleaning n lower the text to prepare input for CB DNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaningData (text):\n",
    "    text=text.lower()\n",
    "    text=re.sub(r\"i'm\",\" i am\",text)\n",
    "    text=re.sub(r\"he's\",\" he is\",text)\n",
    "    text=re.sub(r\"she's\",\" she is\",text)\n",
    "    text=re.sub(r\"that's\",\" that is\",text)\n",
    "    text=re.sub(r\"what's\",\" what is\",text)\n",
    "    text=re.sub(r\"where's\",\" where is\",text)\n",
    "    text=re.sub(r\"their's\",\" their is\",text)\n",
    "    text=re.sub(r\"who's\",\" who is\",text) \n",
    "    text=re.sub(r\"\\*'ll\",\" will\",text)\n",
    "    text=re.sub(r\"\\'ve\",\" have\",text)\n",
    "    text=re.sub(r\"\\'re\",\" are\",text)\n",
    "    text=re.sub(r\"\\'d\",\" would\",text)\n",
    "    text=re.sub(r\"don't\",\" do not\",text)\n",
    "    text=re.sub(r\"we'd\",\" we would\",text)\n",
    "    text=re.sub(r\"won't\",\" will not\",text)\n",
    "    text=re.sub(r\"can't\",\" can not\",text)\n",
    "    text=re.sub(r\"[-()<>\\\"#@/:;{}+=*?,|]\",\"\",text)\n",
    "    text=re.sub(r\"it's\",\" it is\",text)\n",
    "    text=re.sub(r\"you're\",\" you are\",text)\n",
    "    text=re.sub(r\"doesn't\",\" does not\",text)\n",
    "    text=re.sub(r\"we're\",\" we are\",text)\n",
    "    text=re.sub(r\"haven't\",\" have not\",text)\n",
    "    text=re.sub(r\"\\*'s\",\" is\",text)\n",
    "    text=re.sub(r\"aren't\",\" are not\",text)\n",
    "    text=re.sub(r\"didn't \",\" did not\",text)\n",
    "    return text\n",
    "\n",
    "    \n",
    "              \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now cleanng ans que\n",
    "clean_questions=[]\n",
    "clean_answers=[]\n",
    "for question in Questions:\n",
    "    clean_questions.append(cleaningData(question))\n",
    "    \n",
    "for answer in Answers:\n",
    "    clean_answers.append(cleaningData(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting number of arrival of a word in que and ans\n",
    "word2count={}\n",
    "for question in clean_questions:\n",
    "    for word in question.split():\n",
    "        if word not in word2count:\n",
    "            word2count[word]=1\n",
    "        else:\n",
    "            word2count[word]+=1\n",
    "            \n",
    "for answers in clean_answers:\n",
    "    for word in answers.split():\n",
    "        if word not in word2count:\n",
    "            word2count[word]=1\n",
    "        else:\n",
    "            word2count[word]+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=20\n",
    "que_word2int={}\n",
    "word_num=0\n",
    "for word,count in word2count.items(): #key:value\n",
    "    if count>=threshold:\n",
    "        que_word2int[word]=word_num\n",
    "        word_num+=1\n",
    "        \n",
    "ans_word2int={}\n",
    "word_num=0\n",
    "for word,count in word2count.items(): #key:value\n",
    "    if count>=threshold:\n",
    "        ans_word2int[word]=word_num\n",
    "        word_num+=1\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for a in zip(clean_questions,clean_answers):\\n    print(a)\\n    print('\\n'*2)\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for a in zip(clean_questions,clean_answers):\n",
    "    print(a)\n",
    "    print('\\n'*2)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#que_word2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=['<PAD>','<EOS>','<OUT>','<SOS>']\n",
    "for token in tokens:\n",
    "    que_word2int[token]=len(que_word2int)+1\n",
    "    \n",
    "for token in tokens:\n",
    "    ans_word2int[token]=len(ans_word2int)+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#que_word2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_int2word_ivr= {w_i:w for w,w_i in ans_word2int.items()} # inversing the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ans_int2word_ivr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(clean_answers)):  # adding ending tokken for decoder \n",
    "    clean_answers[i]+='<EOS>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "que2int=[] \n",
    "for question in clean_questions:\n",
    "    ints=[]\n",
    "    for word in question.split():\n",
    "        if word not in que_word2int:\n",
    "            ints.append(que_word2int['<OUT>'])\n",
    "        else:\n",
    "            ints.append(que_word2int[word])\n",
    "    que2int.append(ints)\n",
    "    \n",
    "ans2int=[] \n",
    "for answer in clean_answers:\n",
    "    ints=[]\n",
    "    for word in answer.split():\n",
    "        if word not in ans_word2int:\n",
    "            ints.append(ans_word2int['<OUT>'])\n",
    "        else:\n",
    "            ints.append(ans_word2int[word])\n",
    "    ans2int.append(ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_clean_que=[]\n",
    "sort_clean_ans=[]\n",
    "for lenghth in range(1,25+1):   # 1,26\n",
    "    for i in enumerate(que2int):\n",
    "        if len(i[1])==lenghth:\n",
    "            sort_clean_que.append(que2int[i[0]])\n",
    "            sort_clean_ans.append(ans2int[i[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answers\t Lines\t Questions\t a\t ans2int\t ans_int2word_ivr\t ans_word2int\t answer\t answers\t \n",
      "c\t clean_answers\t clean_questions\t cleaningData\t conver\t conversation\t conversationIds\t count\t i\t \n",
      "id2line\t ints\t l\t lenghth\t line\t np\t os\t pd\t que2int\t \n",
      "que_word2int\t question\t re\t sort_clean_ans\t sort_clean_que\t tf\t threshold\t time\t token\t \n",
      "tokens\t word\t word2count\t word_num\t \n"
     ]
    }
   ],
   "source": [
    "who\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upto this point data preprocessing is done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upto this point data preprocessing is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inputs():\n",
    "    inputs=tf.placeholder(tf.int32,[none][none],name='input')\n",
    "    targets=tf.placeholder(tf.int32,[none][none],name='target')\n",
    "    lr=tf.placeholder(tf.float32,name='learning_rate')\n",
    "    keep_prob=tf.placeholder(tf.float32,name='keep_prob')\n",
    "    return  inputs,targets,lr,keep_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now tensorflow and real chat bot development starts from here, see the 2nd part"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
